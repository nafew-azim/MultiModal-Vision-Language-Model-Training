# -*- coding: utf-8 -*-
"""llama3_vl_11b.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1M4yTILFhMjcpdgsJLdBYgibsCtskAZHv
"""

##############################
# INSTALL LIBRARIES
##############################
!pip install git+https://github.com/huggingface/transformers.git@main
!pip install -q datasets
!pip install rouge-score
!pip install unsloth
!pip install --upgrade datasets
!pip install --upgrade huggingface_hub
!pip install datasets bitsandbytes kagglehub "kagglehub[pandas-datasets]"
!hf auth login --token TOKEN_HERE

##############################
# IMPORTS
##############################
from unsloth import FastVisionModel
import torch
from datasets import load_dataset
from transformers import TextStreamer
from unsloth.trainer import UnslothVisionDataCollator
from trl import SFTTrainer, SFTConfig
import os
import pandas as pd

os.environ["TORCH_DYNAMO_DISABLE"] = "1"

##############################
# LOAD MODEL & TOKENIZER
##############################
model, tokenizer = FastVisionModel.from_pretrained(
    "unsloth/Llama-3.2-11B-Vision-bnb-4bit",
    load_in_4bit = True,
    use_gradient_checkpointing = "unsloth",
)

model = FastVisionModel.get_peft_model(
    model,
    finetune_vision_layers     = True,
    finetune_language_layers   = True,
    finetune_attention_modules = True,
    finetune_mlp_modules       = True,
    r = 16,
    lora_alpha = 16,
    lora_dropout = 0.0,
    bias = "none",
    random_state = 3407,
    use_rslora = False,
    loftq_config = None,
)

##############################
# LOAD ROCO DATASET
##############################
dataset = load_dataset("eltorio/ROCOv2-radiology")

print(dataset.keys())
train_dataset = dataset["train"]
val_dataset   = dataset["validation"]
test_dataset  = dataset["test"]

print(f"Train set size:      {len(train_dataset)}")
print(f"Validation set size: {len(val_dataset)}")
print(f"Test set size:       {len(test_dataset)}")

instruction = "Provide a description for this image.."

def convert_to_conversation(sample):
    return {
        "messages": [
            {
                "role": "user",
                "content": [
                    {"type": "text", "text": instruction},
                    {"type": "image", "image": sample["image"]}
                ]
            },
            {
                "role": "assistant",
                "content": [{"type": "text", "text": sample["caption"]}]
            }
        ]
    }

converted_dataset = train_dataset.map(convert_to_conversation)

##############################
# OPTIONAL TEST INFERENCE BEFORE TRAINING
##############################
FastVisionModel.for_inference(model)

image = dataset['train'][2]["image"]
instruction = "Provide a description for this image.."

messages = [
    {"role": "user", "content": [
        {"type": "image", "image": image},
        {"type": "text", "text": instruction}
    ]}
]
input_text = tokenizer.apply_chat_template(messages, add_generation_prompt = True)
inputs = tokenizer(
    image,
    input_text,
    add_special_tokens = False,
    return_tensors = "pt",
).to("cuda")

text_streamer = TextStreamer(tokenizer, skip_prompt = True)
_ = model.generate(**inputs, streamer = text_streamer, max_new_tokens = 128,
                   use_cache = True, temperature = 1.5, min_p = 0.1)

##############################
# TRAINING
##############################
FastVisionModel.for_training(model)

trainer = SFTTrainer(
    model = model,
    tokenizer = tokenizer,
    data_collator = UnslothVisionDataCollator(model, tokenizer),
    train_dataset = converted_dataset,
    args = SFTConfig(
        per_device_train_batch_size = 2,
        gradient_accumulation_steps = 4,
        warmup_steps = 5,
        num_train_epochs = 10,
        learning_rate = 2e-5,
        logging_steps = 1,
        optim = "adamw_8bit",
        weight_decay = 0.01,
        lr_scheduler_type = "linear",
        seed = 3407,
        output_dir = "/kaggle/working/llama3_vision_11b_roco_checkpoints",
        report_to = "none",
        remove_unused_columns = False,
        dataset_text_field = "",
        dataset_kwargs = {"skip_prepare_dataset": True},
        max_seq_length = 2048,
        save_strategy = "epoch",
        push_to_hub = True,
        hub_strategy = "every_save",
        hub_model_id = "llama3_vision_11b_roco_lora",
        hub_token = "TOKEN_HERE",
    ),
)

trainer.train()

##############################
# POST-TRAINING INFERENCE
##############################
FastVisionModel.for_inference(model)

image = dataset[0]["image"]
instruction = "You are an expert radiologist. Describe the image in clinical terms."

messages = [
    {"role": "user", "content": [
        {"type": "image", "image": image},
        {"type": "text", "text": instruction}
    ]}
]
input_text = tokenizer.apply_chat_template(messages, add_generation_prompt = True)
inputs = tokenizer(
    image,
    input_text,
    add_special_tokens = False,
    return_tensors = "pt",
).to("cuda")

text_streamer = TextStreamer(tokenizer, skip_prompt = True)
_ = model.generate(**inputs, streamer = text_streamer, max_new_tokens = 128,
                   use_cache = True, temperature = 1.5, min_p = 0.1)

##############################
# SAVE FINAL MODEL
##############################
model.save_pretrained("/kaggle/working/finetuned_llama3_vl_11b_roco_10_epoch")
tokenizer.save_pretrained("/kaggle/working/finetuned_llama3_vl_11b_roco_10_epoch")

# Push to Hub (LoRA only)
model.push_to_hub("finetuned_llama3_vl_11b_roco_10_epoch_lora")
tokenizer.push_to_hub("finetuned_llama3_vl_11b_roco_10_epoch_lora")

# Push merged model
model.push_to_hub_merged(
    "finetuned_llama3_vl_11b_roco_10_epoch_merged",
    tokenizer,
    token="TOKEN_HERE"
)

model.save_pretrained_merged("finetuned_llama3_vl_11b_roco_10_epoch_merged", tokenizer)

print("Training complete and models pushed to Hugging Face.")
